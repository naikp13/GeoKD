{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prithvi 2.0 to U-Net Feature Distillation\n",
    "\n",
    "This notebook demonstrates how to distill knowledge from the Prithvi 2.0 foundation model to a U-Net student model using feature distillation.\n",
    "\n",
    "## Overview\n",
    "- **Teacher Model**: Prithvi 2.0 (100M parameter foundation model)\n",
    "- **Student Model**: U-Net (lightweight architecture)\n",
    "- **Distillation Method**: Feature Distillation\n",
    "- **Dataset**: SEN12MS (Sentinel-1/2 multispectral data)\n",
    "- **Task**: Land cover classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "# Import GeoKD components\n",
    "from src.data.sen12ms_dataset import SEN12MSDataset\n",
    "from teachers.prithvi_loader import PrithviTeacher\n",
    "from students.unet_student import UNetStudent\n",
    "from src.distillation.losses import FeatureDistillation\n",
    "from src.distillation.distiller import GeospatialDistiller\n",
    "from src.evaluation.metrics import GeospatialMetrics\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "config = {\n",
    "    'batch_size': 16,\n",
    "    'learning_rate': 1e-4,\n",
    "    'num_epochs': 50,\n",
    "    'temperature': 4.0,\n",
    "    'alpha': 0.7,  # Weight for distillation loss\n",
    "    'beta': 0.3,   # Weight for task loss\n",
    "    'feature_weight': 1.0,  # Feature distillation weight\n",
    "    'num_classes': 17,  # SEN12MS land cover classes\n",
    "    'input_channels': 13,  # Sentinel-2 bands\n",
    "    'image_size': 256,\n",
    "    'data_path': '/path/to/sen12ms/dataset',\n",
    "    'checkpoint_dir': './checkpoints',\n",
    "    'log_interval': 10\n",
    "}\n",
    "\n",
    "# Create checkpoint directory\n",
    "os.makedirs(config['checkpoint_dir'], exist_ok=True)\n",
    "\n",
    "print('Configuration:')\n",
    "for key, value in config.items():\n",
    "    print(f'  {key}: {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SEN12MS dataset\n",
    "print('Loading SEN12MS dataset...')\n",
    "\n",
    "train_dataset = SEN12MSDataset(\n",
    "    root_dir=config['data_path'],\n",
    "    split='train',\n",
    "    image_size=config['image_size'],\n",
    "    normalize=True\n",
    ")\n",
    "\n",
    "val_dataset = SEN12MSDataset(\n",
    "    root_dir=config['data_path'],\n",
    "    split='val',\n",
    "    image_size=config['image_size'],\n",
    "    normalize=True\n",
    ")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f'Training samples: {len(train_dataset)}')\n",
    "print(f'Validation samples: {len(val_dataset)}')\n",
    "print(f'Training batches: {len(train_loader)}')\n",
    "print(f'Validation batches: {len(val_loader)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize teacher model (Prithvi 2.0)\n",
    "print('Loading Prithvi 2.0 teacher model...')\n",
    "teacher_model = PrithviTeacher(\n",
    "    model_name='prithvi_100M',\n",
    "    num_classes=config['num_classes'],\n",
    "    pretrained=True\n",
    ").to(device)\n",
    "\n",
    "# Freeze teacher model\n",
    "teacher_model.eval()\n",
    "for param in teacher_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "print(f'Teacher model parameters: {sum(p.numel() for p in teacher_model.parameters()):,}')\n",
    "\n",
    "# Initialize student model (U-Net)\n",
    "print('Initializing U-Net student model...')\n",
    "student_model = UNetStudent(\n",
    "    in_channels=config['input_channels'],\n",
    "    num_classes=config['num_classes'],\n",
    "    base_channels=64\n",
    ").to(device)\n",
    "\n",
    "print(f'Student model parameters: {sum(p.numel() for p in student_model.parameters()):,}')\n",
    "\n",
    "# Calculate compression ratio\n",
    "teacher_params = sum(p.numel() for p in teacher_model.parameters())\n",
    "student_params = sum(p.numel() for p in student_model.parameters())\n",
    "compression_ratio = teacher_params / student_params\n",
    "print(f'Compression ratio: {compression_ratio:.2f}x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Distillation Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize feature distillation loss\n",
    "feature_distillation = FeatureDistillation(\n",
    "    teacher_channels=[768, 768, 768, 768],  # Prithvi feature dimensions\n",
    "    student_channels=[64, 128, 256, 512],   # U-Net feature dimensions\n",
    "    temperature=config['temperature'],\n",
    "    feature_weight=config['feature_weight']\n",
    ").to(device)\n",
    "\n",
    "# Initialize distiller\n",
    "distiller = GeospatialDistiller(\n",
    "    teacher_model=teacher_model,\n",
    "    student_model=student_model,\n",
    "    distillation_loss=feature_distillation,\n",
    "    temperature=config['temperature'],\n",
    "    alpha=config['alpha'],\n",
    "    beta=config['beta']\n",
    ")\n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = optim.AdamW(\n",
    "    student_model.parameters(),\n",
    "    lr=config['learning_rate'],\n",
    "    weight_decay=1e-4\n",
    ")\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=config['num_epochs'],\n",
    "    eta_min=1e-6\n",
    ")\n",
    "\n",
    "# Initialize metrics\n",
    "metrics = GeospatialMetrics(num_classes=config['num_classes'])\n",
    "\n",
    "print('Feature distillation setup complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training history\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "val_ious = []\n",
    "\n",
    "best_val_iou = 0.0\n",
    "\n",
    "print('Starting training...')\n",
    "\n",
    "for epoch in range(config['num_epochs']):\n",
    "    # Training phase\n",
    "    student_model.train()\n",
    "    teacher_model.eval()\n",
    "    \n",
    "    train_loss = 0.0\n",
    "    train_pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{config[\"num_epochs\"]} [Train]')\n",
    "    \n",
    "    for batch_idx, (images, targets) in enumerate(train_pbar):\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass through distiller\n",
    "        loss_dict = distiller(images, targets)\n",
    "        total_loss = loss_dict['total_loss']\n",
    "        \n",
    "        # Backward pass\n",
    "        total_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(student_model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += total_loss.item()\n",
    "        \n",
    "        # Update progress bar\n",
    "        if batch_idx % config['log_interval'] == 0:\n",
    "            train_pbar.set_postfix({\n",
    "                'Loss': f'{total_loss.item():.4f}',\n",
    "                'KD': f'{loss_dict[\"kd_loss\"].item():.4f}',\n",
    "                'Feature': f'{loss_dict[\"feature_loss\"].item():.4f}',\n",
    "                'Task': f'{loss_dict[\"task_loss\"].item():.4f}'\n",
    "            })\n",
    "    \n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    \n",
    "    # Validation phase\n",
    "    student_model.eval()\n",
    "    val_loss = 0.0\n",
    "    metrics.reset()\n",
    "    \n",
    "    val_pbar = tqdm(val_loader, desc=f'Epoch {epoch+1}/{config[\"num_epochs\"]} [Val]')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, targets in val_pbar:\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            loss_dict = distiller(images, targets)\n",
    "            val_loss += loss_dict['total_loss'].item()\n",
    "            \n",
    "            # Get student predictions\n",
    "            student_outputs = student_model(images)\n",
    "            predictions = torch.argmax(student_outputs, dim=1)\n",
    "            \n",
    "            # Update metrics\n",
    "            metrics.update(predictions, targets)\n",
    "    \n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    val_metrics = metrics.compute()\n",
    "    val_accuracy = val_metrics['accuracy']\n",
    "    val_iou = val_metrics['mean_iou']\n",
    "    \n",
    "    val_accuracies.append(val_accuracy)\n",
    "    val_ious.append(val_iou)\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Print epoch results\n",
    "    print(f'Epoch {epoch+1}/{config[\"num_epochs\"]}:')\n",
    "    print(f'  Train Loss: {avg_train_loss:.4f}')\n",
    "    print(f'  Val Loss: {avg_val_loss:.4f}')\n",
    "    print(f'  Val Accuracy: {val_accuracy:.4f}')\n",
    "    print(f'  Val mIoU: {val_iou:.4f}')\n",
    "    print(f'  Learning Rate: {scheduler.get_last_lr()[0]:.6f}')\n",
    "    \n",
    "    # Save best model\n",
    "    if val_iou > best_val_iou:\n",
    "        best_val_iou = val_iou\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'student_state_dict': student_model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'best_val_iou': best_val_iou,\n",
    "            'config': config\n",
    "        }, os.path.join(config['checkpoint_dir'], 'best_student_model.pth'))\n",
    "        print(f'  New best model saved! (mIoU: {best_val_iou:.4f})')\n",
    "    \n",
    "    print('-' * 60)\n",
    "\n",
    "print('Training completed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Loss curves\n",
    "axes[0, 0].plot(train_losses, label='Train Loss', color='blue')\n",
    "axes[0, 0].plot(val_losses, label='Val Loss', color='red')\n",
    "axes[0, 0].set_title('Training and Validation Loss')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True)\n",
    "\n",
    "# Accuracy curve\n",
    "axes[0, 1].plot(val_accuracies, label='Val Accuracy', color='green')\n",
    "axes[0, 1].set_title('Validation Accuracy')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Accuracy')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True)\n",
    "\n",
    "# IoU curve\n",
    "axes[1, 0].plot(val_ious, label='Val mIoU', color='purple')\n",
    "axes[1, 0].set_title('Validation Mean IoU')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('mIoU')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True)\n",
    "\n",
    "# Learning rate curve\n",
    "lr_history = [config['learning_rate'] * (0.5 ** (epoch / (config['num_epochs'] / 4))) for epoch in range(len(train_losses))]\n",
    "axes[1, 1].plot(lr_history, label='Learning Rate', color='orange')\n",
    "axes[1, 1].set_title('Learning Rate Schedule')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Learning Rate')\n",
    "axes[1, 1].set_yscale('log')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(config['checkpoint_dir'], 'training_curves.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f'Best validation mIoU: {best_val_iou:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Evaluation and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "checkpoint = torch.load(os.path.join(config['checkpoint_dir'], 'best_student_model.pth'))\n",
    "student_model.load_state_dict(checkpoint['student_state_dict'])\n",
    "student_model.eval()\n",
    "\n",
    "# Evaluate student model\n",
    "print('Evaluating distilled student model...')\n",
    "student_metrics = GeospatialMetrics(num_classes=config['num_classes'])\n",
    "student_metrics.reset()\n",
    "\n",
    "# Evaluate teacher model for comparison\n",
    "print('Evaluating teacher model...')\n",
    "teacher_metrics = GeospatialMetrics(num_classes=config['num_classes'])\n",
    "teacher_metrics.reset()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, targets in tqdm(val_loader, desc='Evaluation'):\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        # Student predictions\n",
    "        student_outputs = student_model(images)\n",
    "        student_preds = torch.argmax(student_outputs, dim=1)\n",
    "        student_metrics.update(student_preds, targets)\n",
    "        \n",
    "        # Teacher predictions\n",
    "        teacher_outputs = teacher_model(images)\n",
    "        teacher_preds = torch.argmax(teacher_outputs, dim=1)\n",
    "        teacher_metrics.update(teacher_preds, targets)\n",
    "\n",
    "# Compute final metrics\n",
    "student_results = student_metrics.compute()\n",
    "teacher_results = teacher_metrics.compute()\n",
    "\n",
    "# Print comparison\n",
    "print('\\n' + '='*60)\n",
    "print('FINAL EVALUATION RESULTS')\n",
    "print('='*60)\n",
    "\n",
    "print('Teacher Model (Prithvi 2.0):')\n",
    "print(f'  Parameters: {teacher_params:,}')\n",
    "print(f'  Accuracy: {teacher_results[\"accuracy\"]:.4f}')\n",
    "print(f'  Mean IoU: {teacher_results[\"mean_iou\"]:.4f}')\n",
    "print(f'  F1 Score: {teacher_results[\"f1_score\"]:.4f}')\n",
    "\n",
    "print('Student Model (U-Net):')\n",
    "print(f'  Parameters: {student_params:,}')\n",
    "print(f'  Accuracy: {student_results[\"accuracy\"]:.4f}')\n",
    "print(f'  Mean IoU: {student_results[\"mean_iou\"]:.4f}')\n",
    "print(f'  F1 Score: {student_results[\"f1_score\"]:.4f}')\n",
    "\n",
    "print('Distillation Results:')\n",
    "print(f'  Compression Ratio: {compression_ratio:.2f}x')\n",
    "print(f'  Accuracy Retention: {(student_results[\"accuracy\"] / teacher_results[\"accuracy\"]) * 100:.1f}%')\n",
    "print(f'  IoU Retention: {(student_results[\"mean_iou\"] / teacher_results[\"mean_iou\"]) * 100:.1f}%')\n",
    "print(f'  F1 Retention: {(student_results[\"f1_score\"] / teacher_results[\"f1_score\"]) * 100:.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Inference Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a sample for inference demonstration\n",
    "sample_images, sample_targets = next(iter(val_loader))\n",
    "sample_images = sample_images[:4].to(device)  # Take first 4 samples\n",
    "sample_targets = sample_targets[:4].to(device)\n",
    "\n",
    "# Perform inference\n",
    "with torch.no_grad():\n",
    "    teacher_outputs = teacher_model(sample_images)\n",
    "    student_outputs = student_model(sample_images)\n",
    "    \n",
    "    teacher_preds = torch.argmax(teacher_outputs, dim=1)\n",
    "    student_preds = torch.argmax(student_outputs, dim=1)\n",
    "\n",
    "# Visualize results\n",
    "fig, axes = plt.subplots(4, 4, figsize=(16, 16))\n",
    "\n",
    "for i in range(4):\n",
    "    # Original image (RGB bands)\n",
    "    rgb_image = sample_images[i][[3, 2, 1]].cpu().numpy()  # RGB bands\n",
    "    rgb_image = np.transpose(rgb_image, (1, 2, 0))\n",
    "    rgb_image = (rgb_image - rgb_image.min()) / (rgb_image.max() - rgb_image.min())\n",
    "    axes[i, 0].imshow(rgb_image)\n",
    "    axes[i, 0].set_title(f'Sample {i+1}: RGB Image')\n",
    "    axes[i, 0].axis('off')\n",
    "    \n",
    "    # Ground truth\n",
    "    axes[i, 1].imshow(sample_targets[i].cpu().numpy(), cmap='tab20')\n",
    "    axes[i, 1].set_title('Ground Truth')\n",
    "    axes[i, 1].axis('off')\n",
    "    \n",
    "    # Teacher prediction\n",
    "    axes[i, 2].imshow(teacher_preds[i].cpu().numpy(), cmap='tab20')\n",
    "    axes[i, 2].set_title('Teacher Prediction')\n",
    "    axes[i, 2].axis('off')\n",
    "    \n",
    "    # Student prediction\n",
    "    axes[i, 3].imshow(student_preds[i].cpu().numpy(), cmap='tab20')\n",
    "    axes[i, 3].set_title('Student Prediction')\n",
    "    axes[i, 3].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(config['checkpoint_dir'], 'inference_examples.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Model Export and Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export student model for deployment\n",
    "print('Exporting student model...')\n",
    "\n",
    "# Save model in different formats\n",
    "export_dir = os.path.join(config['checkpoint_dir'], 'exported_models')\n",
    "os.makedirs(export_dir, exist_ok=True)\n",
    "\n",
    "# 1. PyTorch format\n",
    "torch.save(student_model.state_dict(), os.path.join(export_dir, 'unet_student.pth'))\n",
    "\n",
    "# 2. TorchScript format\n",
    "student_model.eval()\n",
    "example_input = torch.randn(1, config['input_channels'], config['image_size'], config['image_size']).to(device)\n",
    "traced_model = torch.jit.trace(student_model, example_input)\n",
    "traced_model.save(os.path.join(export_dir, 'unet_student_traced.pt'))\n",
    "\n",
    "# 3. ONNX format (optional)\n",
    "try:\n",
    "    torch.onnx.export(\n",
    "        student_model,\n",
    "        example_input,\n",
    "        os.path.join(export_dir, 'unet_student.onnx'),\n",
    "        export_params=True,\n",
    "        opset_version=11,\n",
    "        do_constant_folding=True,\n",
    "        input_names=['input'],\n",
    "        output_names=['output'],\n",
    "        dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}}\n",
    "    )\n",
    "    print('ONNX export successful!')\n",
    "except Exception as e:\n",
    "    print(f'ONNX export failed: {e}')\n",
    "\n",
    "# Save model metadata\n",
    "metadata = {\n",
    "    'model_type': 'UNet Student',\n",
    "    'teacher_model': 'Prithvi 2.0',\n",
    "    'distillation_method': 'Feature Distillation',\n",
    "    'dataset': 'SEN12MS',\n",
    "    'num_classes': config['num_classes'],\n",
    "    'input_channels': config['input_channels'],\n",
    "    'image_size': config['image_size'],\n",
    "    'parameters': student_params,\n",
    "    'compression_ratio': compression_ratio,\n",
    "    'final_accuracy': student_results['accuracy'],\n",
    "    'final_miou': student_results['mean_iou'],\n",
    "    'final_f1': student_results['f1_score'],\n",
    "    'training_config': config\n",
    "}\n",
    "\n",
    "with open(os.path.join(export_dir, 'model_metadata.yaml'), 'w') as f:\n",
    "    yaml.dump(metadata, f, default_flow_style=False)\n",
    "\n",
    "print(f'Models exported to: {export_dir}')\n",
    "print('Available formats:')\n",
    "print('  - unet_student.pth (PyTorch state dict)')\n",
    "print('  - unet_student_traced.pt (TorchScript)')\n",
    "print('  - unet_student.onnx (ONNX)')\n",
    "print('  - model_metadata.yaml (Model information)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
